from llm.generative_model import get_completion
from Database.token_usage_database_update import update_token_usage
from pinecone_vector_database.query import pincone_vector_database_query  
from DASHBOARD.one_adder import increment_column_for_today
import os
# import streamlit as st
import logging

# Set up at the start of your application
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='app.log'
)




"""
This module provides functionality to generate responses using a generative AI model.
Functions:
  generate_response(context: str, user_input: str) -> dict:
    Generates a response based on the provided context and user input using a chat session.
  process_input(user_input: str) -> dict:
    Processes the user input by retrieving relevant documents and generating a response.
"""


def start_chatting(index_name, user_input):
    increment_column_for_today(index_name)

    """
    Process the user input and return the response generated by the AI model.

    Parameters
    ----------
    index_name : str
        The name of the index to use for querying the vector database.
    user_input : str
        The user's input to process.

    Returns
    -------
    str
        The response generated by the AI model.
    """
    # Add debugging logs
    logging.debug(f"Attempting to query Pinecone with index: {index_name}")
    try:
        context = pincone_vector_database_query(user_input, index_name)
    except Exception as e:
        logging.error(f"Error querying Pinecone: {str(e)}")
        raise
    input_query = (f"""Case: {context}\n\n Question: {user_input}""")
    response, response_metadata = get_completion(input_query)

    
    input_token = response_metadata["input_tokens"]  # Input token
    output_token = response_metadata["output_tokens"] # Output token
    update_token_usage(input_token, output_token)  # Update token usage
    return response




# with st.form(key='my_form'):
#     input_text = st.text_input("Enter your query:")
#     submit_button = st.form_submit_button(label='Submit')

# if submit_button:
#     if input_text.strip() == "":
#         st.warning("Please enter a query.")
#     else:
#         with st.spinner('Generating response...'):
#             result = start_chatting(index_id, input_text)
#         st.markdown(result)

# query = "Summarize the document"
# result = start_chatting(index_id, query)
# print(result)